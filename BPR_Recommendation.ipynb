{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rVKS6Xgg18O",
        "outputId": "2e5c3531-d729-4a51-ec1b-8900dea9858f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.5.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=808329 sha256=a88523cbadd8f38494780e5226e492761ea2a824b5ed62256215204960d441e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.8.30)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install lightfm\n",
        "!pip install vaderSentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import coo_matrix\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "EkmslPNghJZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "reviews_df = pd.read_csv('/content/productReviews.csv')\n",
        "products_df = pd.read_csv('/content/productlist.csv')\n"
      ],
      "metadata": {
        "id": "Ejqs-o9zhMfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess reviews for sentiment analysis\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "fc0Hw4gChc4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform sentiment analysis\n",
        "def analyze_sentiment(review):\n",
        "    score = analyzer.polarity_scores(review)['compound']\n",
        "    if score >= 0.05:\n",
        "        return 5  # Positive review -> 5 star rating\n",
        "    elif score <= -0.05:\n",
        "        return 1  # Negative review -> 1 star rating\n",
        "    else:\n",
        "        return 3  # Neutral review -> 3 star rating\n"
      ],
      "metadata": {
        "id": "U0da2cLThgGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply sentiment analysis to generate ratings\n",
        "reviews_df['generated_rating'] = reviews_df['review'].apply(analyze_sentiment)"
      ],
      "metadata": {
        "id": "r_gn65Sqhi7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge reviews with product list\n",
        "merged_df = pd.merge(reviews_df, products_df, on='product_id', how='inner')\n"
      ],
      "metadata": {
        "id": "J7iNB563hlej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for recommendation system\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n"
      ],
      "metadata": {
        "id": "hCQ4WfF3hpR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['user_id_encoded'] = user_encoder.fit_transform(merged_df['Unnamed: 0'])\n",
        "merged_df['product_id_encoded'] = item_encoder.fit_transform(merged_df['product_id'])\n"
      ],
      "metadata": {
        "id": "XxYGTHLEhsNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create interaction matrix for the BPR model\n",
        "interaction_matrix = coo_matrix((merged_df['generated_rating'],\n",
        "                                (merged_df['user_id_encoded'], merged_df['product_id_encoded'])))"
      ],
      "metadata": {
        "id": "zp5fOPYphvlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Bayesian Personalized Ranking (BPR) model\n",
        "bpr_model = LightFM(loss='bpr')"
      ],
      "metadata": {
        "id": "m91wOBwth0jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "train_matrix, test_matrix = train_test_split(interaction_matrix, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "DEtaJMHgh2_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the BPR model\n",
        "bpr_model.fit(train_matrix, epochs=30, num_threads=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6iz1nOrh5-2",
        "outputId": "fc498b02-145c-41f3-d01c-962978871e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x79240d606410>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recommend similar products\n",
        "def recommend_products(product_id, model, interaction_matrix, n=5):\n",
        "    product_encoded = item_encoder.transform([product_id])\n",
        "    scores = model.predict(0, np.arange(interaction_matrix.shape[1]), item_ids=product_encoded)\n",
        "    product_ids = np.argsort(-scores)[:n]\n",
        "    recommended_products = item_encoder.inverse_transform(product_ids)\n",
        "\n",
        "    # Exclude the input product from recommendations\n",
        "    return [p for p in recommended_products if p != product_id][:n]"
      ],
      "metadata": {
        "id": "SkqGNjpvh88D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# Prepare the interaction matrix (ensure this part is correct)\n",
        "interaction_matrix = coo_matrix((merged_df['generated_rating'],\n",
        "                                (merged_df['user_id_encoded'], merged_df['product_id_encoded'])))\n",
        "\n",
        "# Initialize the Bayesian Personalized Ranking (BPR) model\n",
        "bpr_model = LightFM(loss='bpr')\n",
        "\n",
        "# Train the BPR model (fitting the interaction matrix)\n",
        "bpr_model.fit(interaction_matrix, epochs=30, num_threads=4)\n",
        "\n",
        "# Function to recommend similar products\n",
        "import numpy as np\n",
        "\n",
        "def recommend_products(product_id, model, interaction_matrix, n=5):\n",
        "    product_encoded = item_encoder.transform([product_id])[0]  # Get encoded product_id\n",
        "    # Predict scores for all items for the same user (user 0 in this case)\n",
        "    scores = model.predict(0, np.arange(interaction_matrix.shape[1]))  # user_id is set to 0 for demo\n",
        "    product_ids = np.argsort(-scores)[:n+1]  # Sort scores in descending order\n",
        "\n",
        "    # Get the original product_ids from encoded ones\n",
        "    recommended_products = item_encoder.inverse_transform(product_ids)\n",
        "\n",
        "    # Exclude the input product from recommendations\n",
        "    return [p for p in recommended_products if p != product_id][:n]\n",
        "\n",
        "\n",
        "product_id_to_recommend = '3935400000000'\n",
        "recommendations = recommend_products(product_id_to_recommend, bpr_model, interaction_matrix)\n",
        "print(f\"Recommended products for {product_id_to_recommend}: {recommendations}\")\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_at_k(bpr_model, interaction_matrix, k=5).mean()\n",
        "print(f'Precision@5: {precision}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_LxV7J9j8YG",
        "outputId": "7a55605c-bdd5-45d7-81a3-5e78804de1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended products for 3935400000000: [4098700000000.0, 4347570000000.0, 4567340000000.0, 4337070000000.0, 4498900000000.0]\n",
            "Precision@5: 0.17741939425468445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_products(product_id, model, interaction_matrix, n=5):\n",
        "    product_encoded = item_encoder.transform([product_id])[0]  # Get encoded product_id\n",
        "    # Predict scores for all items for the same user (user 0 in this case)\n",
        "    scores = model.predict(0, np.arange(interaction_matrix.shape[1]))  # user_id is set to 0 for demo\n",
        "    product_ids = np.argsort(-scores)[:n+10]  # Sort scores in descending order, get more to handle exclusion\n",
        "\n",
        "    # Get the original product_ids from encoded ones\n",
        "    recommended_product_ids = item_encoder.inverse_transform(product_ids)\n",
        "\n",
        "    # Exclude the input product from recommendations\n",
        "    recommended_product_ids = [p for p in recommended_product_ids if p != product_id][:n]\n",
        "\n",
        "    # Get all details from the productlist dataset for the recommended products (limit to n)\n",
        "    recommended_products = products_df[products_df['product_id'].isin(recommended_product_ids)].head(n)\n",
        "    return recommended_products\n",
        "\n",
        "# Example usage\n",
        "product_id_to_recommend = '3935400000000'\n",
        "recommendations = recommend_products(product_id_to_recommend, bpr_model, interaction_matrix)\n",
        "print(f\"Recommended products for {product_id_to_recommend}:\\n{recommendations}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xnJ70m-mNu7",
        "outputId": "4b8ecd5a-b4e6-48ae-fc23-0131bdf721bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended products for 3935400000000:\n",
            "     Unnamed: 0    product_id                                  product_name  \\\n",
            "27           33  4.098700e+12                         Living Cleansing Balm   \n",
            "45           55  4.098700e+12                    Soothing Tea Cleansing Gel   \n",
            "59           69  4.567340e+12                  Green Tangerine Vita C Serum   \n",
            "112         139  4.567340e+12              Green Tangerine Vita C Toner Pad   \n",
            "113         140  4.567340e+12  Green Tangerine Vita C Serum Mask (5 sheets)   \n",
            "\n",
            "      product_brand   price  \\\n",
            "27   Then I Met You     $38   \n",
            "45   Then I Met You     $36   \n",
            "59           GOODAL  $19.99   \n",
            "112          GOODAL     $24   \n",
            "113          GOODAL     $15   \n",
            "\n",
            "                                   product_description product_type  \n",
            "27   Exclusive to Soko Glam!This 12x award-winning ...     Cleanser  \n",
            "45   Exclusive to Soko Glam!Founder Charlotte Cho's...     Cleanser  \n",
            "59   A fast favorite, this gel-like serum is packed...        Serum  \n",
            "112  In a quick swipe, you’ll be exfoliating, moist...        Toner  \n",
            "113  Brighten and hydrate skin quickly and effectiv...         Mask  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XimbSIryc61K",
        "outputId": "10f5805a-6f2a-4d7b-bcd4-d3ea9071c5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357284 sha256=0e29fa684a4dad941cf53d59f125e29ac3e391cfe084227523cb054cd8b5a5fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Precision@K and Recall@K Evaluation\n",
        "precision = precision_at_k(bpr_model, interaction_matrix, k=5).mean()\n",
        "recall = recall_at_k(bpr_model, interaction_matrix, k=5).mean()\n",
        "\n",
        "print(f'Precision@5: {precision}')\n",
        "print(f'Recall@5: {recall}')\n",
        "\n",
        "# Convert the interaction matrix to CSR format for efficient row indexing\n",
        "interaction_matrix_csr = interaction_matrix.tocsr()\n",
        "\n",
        "def mean_average_precision(model, interaction_matrix):\n",
        "    map_scores = []\n",
        "    for user_id in range(interaction_matrix.shape[0]):\n",
        "        # Predict scores for all items for the given user\n",
        "        predictions = model.predict(user_id, np.arange(interaction_matrix.shape[1]))\n",
        "\n",
        "        # Get the relevant items for this user\n",
        "        relevant = interaction_matrix[user_id].toarray().ravel() > 0  # Convert to dense array\n",
        "\n",
        "        # Sort items by predicted scores in descending order\n",
        "        ranked_indices = np.argsort(-predictions)\n",
        "        average_precision = 0\n",
        "        hits = 0\n",
        "\n",
        "        # Calculate average precision\n",
        "        for i, idx in enumerate(ranked_indices):\n",
        "            if relevant[idx]:\n",
        "                hits += 1\n",
        "                average_precision += hits / (i + 1)\n",
        "\n",
        "        if hits > 0:\n",
        "            average_precision /= hits\n",
        "        map_scores.append(average_precision)\n",
        "\n",
        "    return np.mean(map_scores)\n",
        "\n",
        "# Compute MAP with the CSR-formatted interaction matrix\n",
        "map_score = mean_average_precision(bpr_model, interaction_matrix_csr)\n",
        "print(f'MAP: {map_score}')\n",
        "\n",
        "# Convert the interaction matrix to CSR format for efficient row indexing\n",
        "interaction_matrix_csr = interaction_matrix.tocsr()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RqzG3m5cyha",
        "outputId": "6fd31b66-dfd5-4f41-f6d3-db2d50ac62fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@5: 0.17741939425468445\n",
            "Recall@5: 0.020119000446041778\n",
            "MAP: 0.8583524151899898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "def compute_ndcg(model, interaction_matrix, k=5):\n",
        "    y_true = []\n",
        "    y_score = []\n",
        "\n",
        "    for user_id in range(interaction_matrix.shape[0]):\n",
        "        true_ratings = interaction_matrix.getrow(user_id).toarray().flatten()\n",
        "        predictions = model.predict(user_id, np.arange(interaction_matrix.shape[1]))\n",
        "\n",
        "        # Add true relevance and predicted scores for NDCG\n",
        "        y_true.append(true_ratings)\n",
        "        y_score.append(predictions)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_score = np.array(y_score)\n",
        "\n",
        "    # Compute NDCG at K\n",
        "    ndcg = ndcg_score(y_true, y_score, k=k)\n",
        "    return ndcg\n",
        "\n",
        "# Compute NDCG at K (e.g., k=5)\n",
        "ndcg_score_value = compute_ndcg(bpr_model, interaction_matrix, k=5)\n",
        "print(f'NDCG@5: {ndcg_score_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KJ7XE52g1p7",
        "outputId": "087e56b4-aef0-47f4-f813-0c8ae2e5b8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@5: 0.862412855616766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hit_rate_at_k(model, interaction_matrix, k=5):\n",
        "    hit_rate = 0.0\n",
        "    for user_id in range(interaction_matrix.shape[0]):\n",
        "        true_ratings = interaction_matrix.getrow(user_id).toarray().flatten()\n",
        "        predictions = model.predict(user_id, np.arange(interaction_matrix.shape[1]))\n",
        "\n",
        "        # Get top-K recommended items\n",
        "        top_k_items = np.argsort(-predictions)[:k]\n",
        "\n",
        "        # Check if there are any hits in the top-K recommendations\n",
        "        if np.any(true_ratings[top_k_items] > 0):\n",
        "            hit_rate += 1\n",
        "\n",
        "    # Compute average hit rate\n",
        "    return hit_rate / interaction_matrix.shape[0]\n",
        "\n",
        "# Compute Hit Rate at K (e.g., k=5)\n",
        "hit_rate_value = compute_hit_rate_at_k(bpr_model, interaction_matrix, k=5)\n",
        "print(f'Hit Rate@5: {hit_rate_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl6EHoxMhfHI",
        "outputId": "b94c9f66-ff10-4a81-da9b-1ea2736eff20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit Rate@5: 0.8870967741935484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mrr_at_k(model, interaction_matrix, k=5):\n",
        "    mrr = 0.0\n",
        "    for user_id in range(interaction_matrix.shape[0]):\n",
        "        true_ratings = interaction_matrix.getrow(user_id).toarray().flatten()\n",
        "        predictions = model.predict(user_id, np.arange(interaction_matrix.shape[1]))\n",
        "\n",
        "        # Get top-K recommended items\n",
        "        top_k_items = np.argsort(-predictions)[:k]\n",
        "\n",
        "        # Find the rank of the first relevant item\n",
        "        relevant_ranks = [rank + 1 for rank, item in enumerate(top_k_items) if true_ratings[item] > 0]\n",
        "\n",
        "        if relevant_ranks:\n",
        "            # Add reciprocal of the first relevant rank\n",
        "            mrr += 1 / min(relevant_ranks)\n",
        "\n",
        "    # Compute the average MRR across all users\n",
        "    return mrr / interaction_matrix.shape[0]\n",
        "\n",
        "# Compute MRR at K (e.g., k=5)\n",
        "mrr_at_k_value = compute_mrr_at_k(bpr_model, interaction_matrix, k=5)\n",
        "print(f'MRR@5: {mrr_at_k_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkxW7o5GhjV2",
        "outputId": "fa1f91e8-8b64-4e8f-a087-e0d485382e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR@5: 0.8539426523297492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_coverage_at_k(model, interaction_matrix, k=5):\n",
        "    recommended_items = set()\n",
        "\n",
        "    for user_id in range(interaction_matrix.shape[0]):\n",
        "        predictions = model.predict(user_id, np.arange(interaction_matrix.shape[1]))\n",
        "\n",
        "        # Get top-K recommended items\n",
        "        top_k_items = np.argsort(-predictions)[:k]\n",
        "\n",
        "        # Add recommended items to the set\n",
        "        recommended_items.update(top_k_items)\n",
        "\n",
        "    # Compute coverage as the proportion of unique recommended items\n",
        "    return len(recommended_items) / interaction_matrix.shape[1]\n",
        "\n",
        "# Compute Coverage at K (e.g., k=5)\n",
        "coverage_value = compute_coverage_at_k(bpr_model, interaction_matrix, k=5)\n",
        "print(f'Coverage@5: {coverage_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vANPbl7hhmnj",
        "outputId": "c098ec91-05a8-460e-c880-1120ba434bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage@5: 0.8207547169811321\n"
          ]
        }
      ]
    }
  ]
}