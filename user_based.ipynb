{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAhCwAhy-6mt",
        "outputId": "bc66bfe1-84ea-4c67-df7b-14f2fb241a11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357285 sha256=86e059778ae7251482b1e3b623bb5a95639b0da9b221ac2c3933da877bce3cfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-h4BLpD_Cai"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4GnH_c8_FO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33550867-7106-447e-afcd-22d095ee6246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Install packages\n",
        "os.system('pip install textblob')\n",
        "os.system('pip install scikit-surprise')\n",
        "os.system('pip install pandas numpy')\n",
        "\n",
        "# Download TextBlob corpora\n",
        "from textblob import download_corpora\n",
        "download_corpora.download_all()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the product reviews dataset\n",
        "product_reviews = pd.read_csv('/content/productReviews.csv')\n",
        "product_list=pd.read_csv('/content/productlist.csv')\n",
        "# Step 1: Generate random user IDs\n",
        "# Define number of users you want to simulate\n",
        "num_users = 1000\n",
        "\n",
        "# Assign a random user_id to each review, where similar user_id can be repeated for different products\n",
        "product_reviews['user_id'] = np.random.randint(1, num_users + 1, product_reviews.shape[0])\n",
        "\n",
        "# Check the dataset with user_id\n",
        "print(product_reviews.head())\n",
        "print(product_list.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deNbaFyYCD1I",
        "outputId": "77b36eb7-2d0b-41ec-a137-5cf27f8fe51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sno    product_id                                             review  \\\n",
            "0    0  4.669760e+12  This makes my skin smooth and soft and is ligh...   \n",
            "1    1  4.669760e+12  Love the silky texture. It's very lightweight ...   \n",
            "2    2  4.669760e+12  I’ve been trying to find a moisturizer that wo...   \n",
            "3    3  4.669760e+12  HYRAM made me buy it and I’m on my second bott...   \n",
            "4    4  4.669760e+12  It's a nice moisturizer I personally will use ...   \n",
            "\n",
            "   user_id  \n",
            "0      308  \n",
            "1      920  \n",
            "2      534  \n",
            "3      131  \n",
            "4      107  \n",
            "   Unnamed: 0    product_id           product_name  product_brand price  \\\n",
            "0           0  6.562640e+12             VITALIFT-A  Dr. Different   $42   \n",
            "1           1  6.562640e+12       VITALIFT-A Forte  Dr. Different   $52   \n",
            "2           2  6.562640e+12  VITALIFT-A Eye & Neck  Dr. Different   $40   \n",
            "3           3  6.592230e+12   Great Barrier Relief    KraveBeauty   $28   \n",
            "4           4  6.535230e+12    Oasis Soothing Mask      DR ALTHEA   $18   \n",
            "\n",
            "                                 product_description           product_type  \n",
            "0  This night-time skin treatment is ideal for th...  Other/Spot Treatments  \n",
            "1  Those that need an extra boost to smooth out f...  Other/Spot Treatments  \n",
            "2  For those looking to target fine lines and wri...          Eye Treatment  \n",
            "3  This creamy serum fights off environmental agg...  Other/Spot Treatments  \n",
            "4  This calming mask delivers intensive moisture ...                   Mask  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Generate ratings from review sentiment\n",
        "def sentiment_to_rating(review_text):\n",
        "    # Using TextBlob to perform sentiment analysis\n",
        "    sentiment = TextBlob(review_text).sentiment.polarity\n",
        "\n",
        "    # Convert sentiment polarity (-1 to 1) to rating scale (1 to 5)\n",
        "    rating = round((sentiment + 1) * 2.5)  # Scale sentiment from (-1, 1) to (1, 5)\n",
        "    return rating\n",
        "\n",
        "# Apply the sentiment_to_rating function to generate the 'rating' column\n",
        "product_reviews['rating'] = product_reviews['review'].apply(sentiment_to_rating)\n",
        "\n",
        "# Check the updated dataset with generated ratings\n",
        "print(product_reviews[['user_id', 'product_id', 'rating']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLiPK-KuCTJl",
        "outputId": "9c22551a-739e-40ca-9445-1252e93a3b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id    product_id  rating\n",
            "0      308  4.669760e+12       3\n",
            "1      920  4.669760e+12       3\n",
            "2      534  4.669760e+12       3\n",
            "3      131  4.669760e+12       4\n",
            "4      107  4.669760e+12       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Prepare the data for collaborative filtering\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(product_reviews[['user_id', 'product_id', 'rating']], reader)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Define a user-based collaborative filtering model with Pearson similarity\n",
        "sim_options = {\n",
        "    'name': 'pearson_baseline',  # Using Pearson similarity\n",
        "    'user_based': True  # User-based collaborative filtering\n",
        "}\n",
        "user_knn_model = KNNBasic(sim_options=sim_options)\n",
        "\n",
        "# Train the model\n",
        "user_knn_model.fit(trainset)\n",
        "\n",
        "# Test the model\n",
        "predictions = user_knn_model.test(testset)\n",
        "accuracy.rmse(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnjDzWtxFj9J",
        "outputId": "35f3bcc4-5583-4abb-d9ff-326373b361ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.6846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6846177374537139"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Recommend products for a specific user\n",
        "def recommend_products_for_user(user_id, n=5):\n",
        "    product_ids = product_reviews['product_id'].unique()\n",
        "\n",
        "    # Predict ratings for all products the user has not rated yet\n",
        "    predicted_ratings = []\n",
        "    for product_id in product_ids:\n",
        "        prediction = user_knn_model.predict(user_id, product_id)\n",
        "        predicted_ratings.append((product_id, prediction.est))\n",
        "\n",
        "    # Sort the products by the predicted rating\n",
        "    predicted_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top n recommendations\n",
        "    recommended_product_ids = [x[0] for x in predicted_ratings[:n]]\n",
        "\n",
        "    # Fetch product details from product_list for these recommendations\n",
        "    recommended_products = product_list[product_list['product_id'].isin(recommended_product_ids)]\n",
        "    return recommended_products\n",
        "\n",
        "# Example usage: Recommend products for a specific user\n",
        "user_id_to_recommend = 400  # Replace with an actual user ID from your dataset\n",
        "recommendations = recommend_products_for_user(user_id_to_recommend)\n",
        "print(f\"Recommended products for user {user_id_to_recommend}:\\n{recommendations}\")\n"
      ],
      "metadata": {
        "id": "G0s24u_GCd24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75414fc0-5e19-453b-825b-19af72879492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended products for user 400:\n",
            "     Unnamed: 0    product_id  \\\n",
            "88          110  4.480000e+12   \n",
            "131         170  1.706910e+12   \n",
            "148         197  4.477080e+12   \n",
            "151         200  4.422860e+12   \n",
            "189         248  1.888570e+12   \n",
            "\n",
            "                                          product_name product_brand   price  \\\n",
            "88                      Charcoal Bubble Cleansing Pads      MEDIHEAL  $11.99   \n",
            "131               Ultra Vitalizing Snail Essence Water      DEWYTREE     $38   \n",
            "148                             Fermentation Mask Pack        BENTON      $3   \n",
            "151                MadeCera Cream Double Essence Toner    SKINRX LAB     $26   \n",
            "189  SUR.MEDIC+ Super Hyaluronic 100TM Amino Acid C...    SUR.MEDIC+     $20   \n",
            "\n",
            "                                   product_description product_type  \n",
            "88   An innovative and simple one-step dual-sided c...     Cleanser  \n",
            "131  This lightweight yet powerful essence hydrates...      Essence  \n",
            "148  This premium mask pack from Benton contains th...         Mask  \n",
            "151  Exclusive to Soko Glam!Known as the “strawberr...      Essence  \n",
            "189  This gentle cleanser effectively removes impur...     Cleanser  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Prepare the data for collaborative filtering\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(product_reviews[['user_id', 'product_id', 'rating']], reader)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Define a user-based collaborative filtering model with Pearson similarity\n",
        "sim_options = {\n",
        "    'name': 'pearson_baseline',  # Using Pearson similarity\n",
        "    'user_based': True  # User-based collaborative filtering\n",
        "}\n",
        "user_knn_model = KNNBasic(sim_options=sim_options)\n",
        "\n",
        "# Train the model\n",
        "user_knn_model.fit(trainset)\n",
        "\n",
        "# Test the model\n",
        "predictions = user_knn_model.test(testset)\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Function to evaluate precision@k and recall@k\n",
        "def precision_recall_at_k(predictions, k=5, threshold=3.5):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Get top-N recommendations for each user\n",
        "    def get_top_n(predictions, n=5):\n",
        "        top_n = defaultdict(list)\n",
        "        for uid, iid, true_r, est, _ in predictions:\n",
        "            top_n[uid].append((iid, est))\n",
        "        for uid, user_ratings in top_n.items():\n",
        "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "            top_n[uid] = user_ratings[:n]\n",
        "        return top_n\n",
        "\n",
        "    top_n = get_top_n(predictions, n=k)\n",
        "\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "\n",
        "    # Iterate through testset using predictions instead of unpacking testset\n",
        "    relevant_items_per_user = defaultdict(list)\n",
        "    for uid, iid, true_r in testset:\n",
        "        if true_r >= threshold:\n",
        "            relevant_items_per_user[uid].append(iid)\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        relevant_items = relevant_items_per_user[uid]\n",
        "        recommended_items = [iid for (iid, _) in user_ratings]\n",
        "\n",
        "        num_relevant_and_recommended = len(set(recommended_items) & set(relevant_items))\n",
        "        precision = num_relevant_and_recommended / len(recommended_items) if recommended_items else 0\n",
        "        recall = num_relevant_and_recommended / len(relevant_items) if relevant_items else 0\n",
        "\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_recall = np.mean(recalls)\n",
        "\n",
        "    return avg_precision, avg_recall\n",
        "\n",
        "\n",
        "# Function to compute Mean Average Precision (MAP)\n",
        "def mean_average_precision(predictions):\n",
        "    from collections import defaultdict\n",
        "    user_map_scores = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        user_map_scores[uid].append((iid, true_r, est))\n",
        "\n",
        "    map_scores = []\n",
        "    for user_ratings in user_map_scores.values():\n",
        "        user_ratings.sort(key=lambda x: x[2], reverse=True)  # Sort by predicted score\n",
        "        num_relevant = 0\n",
        "        score = 0\n",
        "        for rank, (iid, true_r, _) in enumerate(user_ratings):\n",
        "            if true_r >= 3.5:  # Consider threshold as relevant\n",
        "                num_relevant += 1\n",
        "                score += num_relevant / (rank + 1)\n",
        "        if num_relevant > 0:\n",
        "            map_scores.append(score / num_relevant)\n",
        "\n",
        "    return np.mean(map_scores)\n",
        "\n",
        "# Function to compute AUC (Area Under the ROC Curve)\n",
        "def compute_auc(predictions):\n",
        "    y_true = [1 if true_r >= 3.5 else 0 for (_, _, true_r, _, _) in predictions]\n",
        "    y_scores = [est for (_, _, _, est, _) in predictions]\n",
        "    return roc_auc_score(y_true, y_scores)\n",
        "\n",
        "# Evaluate metrics\n",
        "precision, recall = precision_recall_at_k(predictions, k=5)\n",
        "map_score = mean_average_precision(predictions)\n",
        "auc_score = compute_auc(predictions)\n",
        "\n",
        "print(f\"Precision@K: {precision}\")\n",
        "print(f\"Recall@K: {recall}\")\n",
        "print(f\"MAP: {map_score}\")\n",
        "print(f\"AUC: {auc_score}\")\n",
        "\n",
        "# Recommend products for a specific user\n",
        "def recommend_products_for_user(user_id, n=5):\n",
        "    product_ids = product_reviews['product_id'].unique()\n",
        "\n",
        "    # Predict ratings for all products the user has not rated yet\n",
        "    predicted_ratings = []\n",
        "    for product_id in product_ids:\n",
        "        prediction = user_knn_model.predict(user_id, product_id)\n",
        "        predicted_ratings.append((product_id, prediction.est))\n",
        "\n",
        "    # Sort the products by the predicted rating\n",
        "    predicted_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top n recommendations\n",
        "    recommended_product_ids = [x[0] for x in predicted_ratings[:n]]\n",
        "\n",
        "    # Fetch product details from product_list for these recommendations\n",
        "    recommended_products = product_list[product_list['product_id'].isin(recommended_product_ids)]\n",
        "    return recommended_products\n",
        "\n",
        "# Example usage: Recommend products for a specific user\n",
        "user_id_to_recommend = 400  # Replace with an actual user ID from your dataset\n",
        "recommendations = recommend_products_for_user(user_id_to_recommend)\n",
        "print(f\"Recommended products for user {user_id_to_recommend}:\\n{recommendations}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puhd3J1-Zx65",
        "outputId": "976acd17-7099-4a3e-dab7-74e547c8ce99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.6633\n",
            "Precision@K: 0.20468856947296374\n",
            "Recall@K: 0.5000855578370978\n",
            "MAP: 0.60098826975022\n",
            "AUC: 0.5226616129272081\n",
            "Recommended products for user 400:\n",
            "     Unnamed: 0    product_id  \\\n",
            "80          102  4.620650e+12   \n",
            "81          103  4.620650e+12   \n",
            "88          110  4.480000e+12   \n",
            "131         170  1.706910e+12   \n",
            "148         197  4.477080e+12   \n",
            "189         248  1.888570e+12   \n",
            "\n",
            "                                          product_name product_brand   price  \\\n",
            "80                  Houttuynia Cordata Calming Essence        GOODAL     $30   \n",
            "81           Houttuynia Cordata Calming Moisture Cream        GOODAL     $24   \n",
            "88                      Charcoal Bubble Cleansing Pads      MEDIHEAL  $11.99   \n",
            "131               Ultra Vitalizing Snail Essence Water      DEWYTREE     $38   \n",
            "148                             Fermentation Mask Pack        BENTON      $3   \n",
            "189  SUR.MEDIC+ Super Hyaluronic 100TM Amino Acid C...    SUR.MEDIC+     $20   \n",
            "\n",
            "                                   product_description product_type  \n",
            "80   With a 97.5% concentration of houttuynia corda...      Essence  \n",
            "81   This lightweight cream from Goodal is the answ...  Moisturizer  \n",
            "88   An innovative and simple one-step dual-sided c...     Cleanser  \n",
            "131  This lightweight yet powerful essence hydrates...      Essence  \n",
            "148  This premium mask pack from Benton contains th...         Mask  \n",
            "189  This gentle cleanser effectively removes impur...     Cleanser  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_at_k(predictions, k=5, threshold=3.5):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    def dcg_at_k(ranked_list, k):\n",
        "        dcg = 0\n",
        "        for i, (iid, _) in enumerate(ranked_list[:k]):\n",
        "            if iid in relevant_items:\n",
        "                dcg += 1 / np.log2(i + 2)  # Discounted by rank position\n",
        "        return dcg\n",
        "\n",
        "    # Get top-N recommendations for each user\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Compute NDCG@K for each user\n",
        "    ndcg_scores = []\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        relevant_items = set([iid for iid, true_r in product_reviews[product_reviews['user_id'] == uid][['product_id', 'rating']].values if true_r >= threshold])\n",
        "        dcg = dcg_at_k(user_ratings, k)\n",
        "        ideal_dcg = dcg_at_k(sorted(user_ratings, key=lambda x: x[1], reverse=True), k)\n",
        "        ndcg_scores.append(dcg / ideal_dcg if ideal_dcg > 0 else 0)\n",
        "\n",
        "    return np.mean(ndcg_scores)\n",
        "\n",
        "# Example usage:\n",
        "ndcg_score = ndcg_at_k(predictions, k=5)\n",
        "print(f\"NDCG@K: {ndcg_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoRgsKhAig9w",
        "outputId": "277a846a-7e2f-4f9f-988e-547e9a250087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@K: 0.6129363449691991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_at_k(predictions, k=5, threshold=3.5):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Get top-N recommendations for each user\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        relevant_items = set([iid for iid, true_r in product_reviews[product_reviews['user_id'] == uid][['product_id', 'rating']].values if true_r >= threshold])\n",
        "        recommended_items = set([iid for iid, _ in user_ratings[:k]])\n",
        "\n",
        "        tp = len(relevant_items & recommended_items)\n",
        "        fp = len(recommended_items) - tp\n",
        "        fn = len(relevant_items) - tp\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "        if precision + recall > 0:\n",
        "            f1 = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            f1 = 0\n",
        "\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    avg_f1 = np.mean([2 * p * r / (p + r) if (p + r) > 0 else 0 for p, r in zip(precisions, recalls)])\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "# Example usage:\n",
        "f1_score = f1_score_at_k(predictions, k=5)\n",
        "print(f\"F1-Score@K: {f1_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YYMggz5jOQA",
        "outputId": "151b50ea-80c6-414c-a487-9f3e048e3dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score@K: 0.2525509170273031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hit_rate_at_k(predictions, k=5, threshold=3.5):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Get top-N recommendations for each user\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Calculate Hit Rate\n",
        "    hit_rates = []\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        relevant_items = set([iid for iid, true_r in product_reviews[product_reviews['user_id'] == uid][['product_id', 'rating']].values if true_r >= threshold])\n",
        "        recommended_items = set([iid for iid, _ in user_ratings[:k]])\n",
        "\n",
        "        hit = 1 if len(relevant_items & recommended_items) > 0 else 0\n",
        "        hit_rates.append(hit)\n",
        "\n",
        "    return np.mean(hit_rates)\n",
        "\n",
        "# Example usage:\n",
        "hit_rate = hit_rate_at_k(predictions, k=5)\n",
        "print(f\"Hit Rate@K: {hit_rate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLg9tLurjSP2",
        "outputId": "03dc98c6-6cab-46bb-e60f-053c052dece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit Rate@K: 0.6129363449691991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def coverage_at_k(predictions, k=5):\n",
        "    recommended_items = set()\n",
        "    total_items = len(product_list['product_id'].unique())\n",
        "\n",
        "    # Get top-N recommendations for each user\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Collect all recommended items\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        recommended_items.update([iid for iid, _ in user_ratings[:k]])\n",
        "\n",
        "    return len(recommended_items) / total_items\n",
        "\n",
        "# Example usage:\n",
        "coverage_score = coverage_at_k(predictions, k=5)\n",
        "print(f\"Coverage@K: {coverage_score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQxRtA9jVeF",
        "outputId": "a2fbf46c-fe96-4dcb-f9fe-cedc8539139c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage@K: 0.9694656488549618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mrr_at_k(predictions, k=5, threshold=3.5):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Get top-N recommendations for each user\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Calculate MRR@K\n",
        "    mrr_scores = []\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        relevant_items = set([iid for iid, true_r in product_reviews[product_reviews['user_id'] == uid][['product_id', 'rating']].values if true_r >= threshold])\n",
        "        rank = -1\n",
        "        for i, (iid, _) in enumerate(user_ratings[:k]):\n",
        "            if iid in relevant_items:\n",
        "                rank = i + 1\n",
        "                break\n",
        "        mrr_scores.append(1 / rank if rank != -1 else 0)\n",
        "\n",
        "    return np.mean(mrr_scores)\n",
        "\n",
        "# Example usage:\n",
        "mrr_score = mrr_at_k(predictions, k=5)\n",
        "print(f\"MRR@K: {mrr_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvd_5ZB8jYIX",
        "outputId": "73777e08-bb65-41cd-88db-16ac72e5943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR@K: 0.4678473648186174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z17PufGQjcXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}